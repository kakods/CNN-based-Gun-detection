{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Application in Colab.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "LnWP9R8hbNAE",
        "xhdIzuQib4rW",
        "3hkusrzQDtHd",
        "niUOqwKkFyvY"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kakods/CNN-based-Gun-detection/blob/master/Application_in_Colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnWP9R8hbNAE",
        "colab_type": "text"
      },
      "source": [
        "# Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK0nTTmUbc7G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai import *\n",
        "from fastai.vision import *\n",
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUUGJ2CGQq3e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from fastai.vision.models.unet import _get_sfs_idxs, model_sizes, hook_outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w42PqSlYUfxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LateralUpsampleMerge(nn.Module):\n",
        "    \"Merge the features coming from the downsample path (in `hook`) with the upsample path.\"\n",
        "    def __init__(self, ch, ch_lat, hook):\n",
        "        super().__init__()\n",
        "        self.hook = hook\n",
        "        self.conv_lat = conv2d(ch_lat, ch, ks=1, bias=True)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        return self.conv_lat(self.hook.stored) + F.interpolate(x, self.hook.stored.shape[-2:], mode='nearest')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4RxtTefTxwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, nf):\n",
        "        super().__init__()\n",
        "        self.conv1 = conv_layer(nf,nf)\n",
        "        self.conv2 = conv_layer(nf,nf)\n",
        "        self.conv=conv_layer(nf, nf, bias=True, norm_type=None) \n",
        "        \n",
        "    def forward(self, x):\n",
        "      x=self.conv(x)\n",
        "      return x + self.conv2(self.conv1(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_bXdsBBUh3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RetinaNet(nn.Module):\n",
        "    \"Implements RetinaNet from https://arxiv.org/abs/1708.02002\"\n",
        "    def __init__(self, encoder:nn.Module, n_classes, final_bias=0., chs=256, n_anchors=9, flatten=True):\n",
        "        super().__init__()\n",
        "        self.n_classes,self.flatten = n_classes,flatten\n",
        "        imsize = (512,512)\n",
        "        sfs_szs = model_sizes(encoder, size=imsize)\n",
        "        sfs_idxs = list(reversed(_get_sfs_idxs(sfs_szs)))\n",
        "        self.sfs = hook_outputs([encoder[i] for i in sfs_idxs])\n",
        "        self.encoder = encoder\n",
        "        self.c5top5 = conv2d(sfs_szs[-1][1], chs, ks=1, bias=True)\n",
        "        self.c5top6 = conv2d(sfs_szs[-1][1], chs, stride=2, bias=True)\n",
        "        self.p6top7 = nn.Sequential(nn.ReLU(), conv2d(chs, chs, stride=2, bias=True))\n",
        "        self.merges = nn.ModuleList([LateralUpsampleMerge(chs, sfs_szs[idx][1], hook) \n",
        "                                     for idx,hook in zip(sfs_idxs[-2:-4:-1], self.sfs[-2:-4:-1])])\n",
        "        self.smoothers = nn.ModuleList([conv2d(chs, chs, 3, bias=True) for _ in range(3)])\n",
        "        self.classifier = self._head_subnet(n_classes, n_anchors, final_bias, chs=chs)\n",
        "        self.box_regressor = self._head_subnet(4, n_anchors, 0., chs=chs)\n",
        "        self.res=conv2d(chs,chs,3,stride=1)\n",
        "        \n",
        "    def _head_subnet(self, n_classes, n_anchors, final_bias=0., n_conv=4, chs=256):\n",
        "        \"Helper function to create one of the subnet for regression/classification.\"\n",
        "        #layers = [ResBlock(chs) for _ in range(n_conv)]\n",
        "        layers = [conv_layer(chs, chs, bias=True, norm_type=None) for _ in range(n_conv)]\n",
        "        layers += [conv2d(chs, n_classes * n_anchors, bias=True)]\n",
        "        layers[-1].bias.data.zero_().add_(final_bias)\n",
        "        layers[-1].weight.data.fill_(0)\n",
        "        return nn.Sequential(*layers)\n",
        "    \n",
        "    def _apply_transpose(self, func, p_states, n_classes):\n",
        "        #Final result of the classifier/regressor is bs * (k * n_anchors) * h * w\n",
        "        #We make it bs * h * w * n_anchors * k then flatten in bs * -1 * k so we can contenate\n",
        "        #all the results in bs * anchors * k (the non flatten version is there for debugging only)\n",
        "        if not self.flatten: \n",
        "            sizes = [[p.size(0), p.size(2), p.size(3)] for p in p_states]\n",
        "            return [func(p).permute(0,2,3,1).view(*sz,-1,n_classes) for p,sz in zip(p_states,sizes)]\n",
        "        else:\n",
        "            return torch.cat([func(p).permute(0,2,3,1).contiguous().view(p.size(0),-1,n_classes) for p in p_states],1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        c5 = self.encoder(x)\n",
        "        p_states = [self.c5top5(c5.clone()), self.c5top6(c5)]\n",
        "        p_states.append(self.p6top7(p_states[-1]))\n",
        "        for merge in self.merges: p_states = [merge(p_states[0])] + p_states\n",
        "        for i, smooth in enumerate(self.smoothers[:3]):\n",
        "            p_states[i] = smooth(p_states[i])\n",
        "        return [self._apply_transpose(self.classifier, p_states, self.n_classes), \n",
        "                self._apply_transpose(self.box_regressor, p_states, 4),\n",
        "                [[p.size(2), p.size(3)] for p in p_states]]\n",
        "    \n",
        "    def __del__(self):\n",
        "        if hasattr(self, \"sfs\"): self.sfs.remove()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRD8PALyUotS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_grid(size):\n",
        "    \"Create a grid of a given `size`.\"\n",
        "    H, W = size if is_tuple(size) else (size,size)\n",
        "    grid = FloatTensor(H, W, 2)\n",
        "    linear_points = torch.linspace(-1+1/W, 1-1/W, W) if W > 1 else tensor([0.])\n",
        "    grid[:, :, 1] = torch.ger(torch.ones(H), linear_points).expand_as(grid[:, :, 0])\n",
        "    linear_points = torch.linspace(-1+1/H, 1-1/H, H) if H > 1 else tensor([0.])\n",
        "    grid[:, :, 0] = torch.ger(linear_points, torch.ones(W)).expand_as(grid[:, :, 1])\n",
        "    return grid.view(-1,2)\n",
        "\n",
        "def show_anchors(ancs, size):\n",
        "    _,ax = plt.subplots(1,1, figsize=(5,5))\n",
        "    ax.set_xticks(np.linspace(-1,1, size[1]+1))\n",
        "    ax.set_yticks(np.linspace(-1,1, size[0]+1))\n",
        "    ax.grid()\n",
        "    ax.scatter(ancs[:,1], ancs[:,0]) #y is first\n",
        "    ax.set_yticklabels([])\n",
        "    ax.set_xticklabels([])\n",
        "    ax.set_xlim(-1,1)\n",
        "    ax.set_ylim(1,-1) #-1 is top, 1 is bottom\n",
        "    for i, (x, y) in enumerate(zip(ancs[:, 1], ancs[:, 0])): ax.annotate(i, xy = (x,y))\n",
        "\n",
        "\n",
        "def create_anchors(sizes, ratios, scales, flatten=True):\n",
        "    \"Create anchor of `sizes`, `ratios` and `scales`.\"\n",
        "    aspects = [[[s*math.sqrt(r), s*math.sqrt(1/r)] for s in scales] for r in ratios]\n",
        "    aspects = torch.tensor(aspects).view(-1,2)\n",
        "    anchors = []\n",
        "    for h,w in sizes:\n",
        "        #4 here to have the anchors overlap.\n",
        "        sized_aspects = 4 * (aspects * torch.tensor([2/h,2/w])).unsqueeze(0)\n",
        "        base_grid = create_grid((h,w)).unsqueeze(1)\n",
        "        n,a = base_grid.size(0),aspects.size(0)\n",
        "        ancs = torch.cat([base_grid.expand(n,a,2), sized_aspects.expand(n,a,2)], 2)\n",
        "        anchors.append(ancs.view(h,w,a,4))\n",
        "    return torch.cat([anc.view(-1,4) for anc in anchors],0) if flatten else anchors\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gt3Hrx7U4mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.cm as cmx\n",
        "import matplotlib.colors as mcolors\n",
        "from cycler import cycler\n",
        "\n",
        "def get_cmap(N):\n",
        "    color_norm  = mcolors.Normalize(vmin=0, vmax=N-1)\n",
        "    return cmx.ScalarMappable(norm=color_norm, cmap='Set3').to_rgba\n",
        "\n",
        "num_color = 12\n",
        "cmap = get_cmap(num_color)\n",
        "color_list = [cmap(float(x)) for x in range(num_color)]\n",
        "\n",
        "def draw_outline(o, lw):\n",
        "    o.set_path_effects([patheffects.Stroke(\n",
        "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
        "\n",
        "def draw_rect(ax, b, color='white'):\n",
        "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n",
        "    draw_outline(patch, 4)\n",
        "\n",
        "def draw_text(ax, xy, txt, sz=14, color='white'):\n",
        "    text = ax.text(*xy, txt,\n",
        "        verticalalignment='top', color=color, fontsize=sz, weight='bold')\n",
        "    draw_outline(text, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzImJ4suU7Td",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_boxes(boxes):\n",
        "    \"Show the `boxes` (size by 4)\"\n",
        "    _, ax = plt.subplots(1,1, figsize=(5,5))\n",
        "    ax.set_xlim(-1,1)\n",
        "    ax.set_ylim(1,-1)\n",
        "    for i, bbox in enumerate(boxes):\n",
        "        bb = bbox.numpy()\n",
        "        rect = [bb[1]-bb[3]/2, bb[0]-bb[2]/2, bb[3], bb[2]]\n",
        "        draw_rect(ax, rect, color=color_list[i%num_color])\n",
        "        draw_text(ax, [bb[1]-bb[3]/2,bb[0]-bb[2]/2], str(i), color=color_list[i%num_color])\n",
        "\n",
        "def activ_to_bbox(acts, anchors, flatten=True):\n",
        "    \"Extrapolate bounding boxes on anchors from the model activations.\"\n",
        "    if flatten:\n",
        "        acts.mul_(acts.new_tensor([[0.1, 0.1, 0.2, 0.2]])) #Can't remember where those scales come from, but they help regularize\n",
        "        centers = anchors[...,2:] * acts[...,:2] + anchors[...,:2]\n",
        "        sizes = anchors[...,2:] * torch.exp(acts[...,:2])\n",
        "        return torch.cat([centers, sizes], -1)\n",
        "    else: return [activ_to_bbox(act,anc) for act,anc in zip(acts, anchors)]\n",
        "    return res\n",
        "def cthw2tlbr(boxes):\n",
        "    \"Convert center/size format `boxes` to top/left bottom/right corners.\"\n",
        "    top_left = boxes[:,:2] - boxes[:,2:]/2\n",
        "    bot_right = boxes[:,:2] + boxes[:,2:]/2\n",
        "    return torch.cat([top_left, bot_right], 1)\n",
        "\n",
        "def intersection(anchors, targets):\n",
        "    \"Compute the sizes of the intersections of `anchors` by `targets`.\"\n",
        "    ancs, tgts = cthw2tlbr(anchors), cthw2tlbr(targets)\n",
        "    a, t = ancs.size(0), tgts.size(0)\n",
        "    ancs, tgts = ancs.unsqueeze(1).expand(a,t,4), tgts.unsqueeze(0).expand(a,t,4)\n",
        "    top_left_i = torch.max(ancs[...,:2], tgts[...,:2])\n",
        "    bot_right_i = torch.min(ancs[...,2:], tgts[...,2:])\n",
        "    sizes = torch.clamp(bot_right_i - top_left_i, min=0) \n",
        "    return sizes[...,0] * sizes[...,1]\n",
        "def IoU_values(anchors, targets):\n",
        "    \"Compute the IoU values of `anchors` by `targets`.\"\n",
        "    inter = intersection(anchors, targets)\n",
        "    anc_sz, tgt_sz = anchors[:,2] * anchors[:,3], targets[:,2] * targets[:,3]\n",
        "    union = anc_sz.unsqueeze(1) + tgt_sz.unsqueeze(0) - inter\n",
        "    return inter/(union+1e-8)\n",
        "def match_anchors(anchors, targets, match_thr=0.5, bkg_thr=0.4):\n",
        "    \"Match `anchors` to targets. -1 is match to background, -2 is ignore.\"\n",
        "    matches = anchors.new(anchors.size(0)).zero_().long() - 2\n",
        "    if targets.numel() == 0: return matches\n",
        "    ious = IoU_values(anchors, targets)\n",
        "    vals,idxs = torch.max(ious,1)\n",
        "    matches[vals < bkg_thr] = -1\n",
        "    matches[vals > match_thr] = idxs[vals > match_thr]\n",
        "    #Overwrite matches with each target getting the anchor that has the max IoU.\n",
        "    #vals,idxs = torch.max(ious,0)\n",
        "    #If idxs contains repetition, this doesn't bug and only the last is considered.\n",
        "    #matches[idxs] = targets.new_tensor(list(range(targets.size(0)))).long()\n",
        "    return matches\n",
        "def tlbr2cthw(boxes):\n",
        "    \"Convert top/left bottom/right format `boxes` to center/size corners.\"\n",
        "    center = (boxes[:,:2] + boxes[:,2:])/2\n",
        "    sizes = boxes[:,2:] - boxes[:,:2]\n",
        "    return torch.cat([center, sizes], 1)\n",
        "\n",
        "def bbox_to_activ(bboxes, anchors, flatten=True):\n",
        "    \"Return the target of the model on `anchors` for the `bboxes`.\"\n",
        "    if flatten:\n",
        "        t_centers = (bboxes[...,:2] - anchors[...,:2]) / anchors[...,2:] \n",
        "        t_sizes = torch.log(bboxes[...,2:] / anchors[...,2:] + 1e-8) \n",
        "        return torch.cat([t_centers, t_sizes], -1).div_(bboxes.new_tensor([[0.1, 0.1, 0.2, 0.2]]))\n",
        "    else: return [activ_to_bbox(act,anc) for act,anc in zip(acts, anchors)]\n",
        "    return res\n",
        "def encode_class(idxs, n_classes):\n",
        "    target = idxs.new_zeros(len(idxs), n_classes).float()\n",
        "    mask = idxs != 0\n",
        "    i1s = LongTensor(list(range(len(idxs))))\n",
        "    target[i1s[mask],idxs[mask]-1] = 1\n",
        "    return target\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ITHHg3DVlHw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RetinaNetFocalLoss(nn.Module):\n",
        "    \n",
        "    def __init__(self, gamma:float=2., alpha:float=0.25,  pad_idx:int=0, scales:Collection[float]=None, \n",
        "                 ratios:Collection[float]=None, reg_loss:LossFunction=F.smooth_l1_loss):\n",
        "        super().__init__()\n",
        "        self.gamma,self.alpha,self.pad_idx,self.reg_loss = gamma,alpha,pad_idx,reg_loss\n",
        "        self.scales = ifnone(scales, [1,2**(-1/3), 2**(-2/3)])\n",
        "        self.ratios = ifnone(ratios, [1/2,1,2])\n",
        "        \n",
        "    def _change_anchors(self, sizes:Sizes) -> bool:\n",
        "        if not hasattr(self, 'sizes'): return True\n",
        "        for sz1, sz2 in zip(self.sizes, sizes):\n",
        "            if sz1[0] != sz2[0] or sz1[1] != sz2[1]: return True\n",
        "        return False\n",
        "    \n",
        "    def _create_anchors(self, sizes:Sizes, device:torch.device):\n",
        "        self.sizes = sizes\n",
        "        self.anchors = create_anchors(sizes, self.ratios, self.scales).to(device)\n",
        "    \n",
        "    def _unpad(self, bbox_tgt, clas_tgt):\n",
        "        i = torch.min(torch.nonzero(clas_tgt-self.pad_idx))\n",
        "        return tlbr2cthw(bbox_tgt[i:]), clas_tgt[i:]-1+self.pad_idx\n",
        "    \n",
        "    def _focal_loss(self, clas_pred, clas_tgt):\n",
        "        encoded_tgt = encode_class(clas_tgt, clas_pred.size(1))\n",
        "        ps = torch.sigmoid(clas_pred.detach())\n",
        "        weights = encoded_tgt * (1-ps) + (1-encoded_tgt) * ps\n",
        "        alphas = (1-encoded_tgt) * self.alpha + encoded_tgt * (1-self.alpha)\n",
        "        weights.pow_(self.gamma).mul_(alphas)\n",
        "        clas_loss = F.binary_cross_entropy_with_logits(clas_pred, encoded_tgt, weights, reduction='sum')\n",
        "        return clas_loss\n",
        "        \n",
        "    def _one_loss(self, clas_pred, bbox_pred, clas_tgt, bbox_tgt):\n",
        "        bbox_tgt, clas_tgt = self._unpad(bbox_tgt, clas_tgt)\n",
        "        matches = match_anchors(self.anchors, bbox_tgt)\n",
        "        bbox_mask = matches>=0\n",
        "        if bbox_mask.sum() != 0:\n",
        "            bbox_pred = bbox_pred[bbox_mask]\n",
        "            bbox_tgt = bbox_tgt[matches[bbox_mask]]\n",
        "            bb_loss = self.reg_loss(bbox_pred, bbox_to_activ(bbox_tgt, self.anchors[bbox_mask]))\n",
        "        else: bb_loss = 0.\n",
        "        matches.add_(1)\n",
        "        clas_tgt = clas_tgt + 1\n",
        "        clas_mask = matches>=0\n",
        "        clas_pred = clas_pred[clas_mask]\n",
        "        clas_tgt = torch.cat([clas_tgt.new_zeros(1).long(), clas_tgt])\n",
        "        clas_tgt = clas_tgt[matches[clas_mask]]\n",
        "        return bb_loss + self._focal_loss(clas_pred, clas_tgt)/torch.clamp(bbox_mask.sum(), min=1.)\n",
        "    \n",
        "    def forward(self, output, bbox_tgts, clas_tgts):\n",
        "        clas_preds, bbox_preds, sizes = output\n",
        "        if self._change_anchors(sizes): self._create_anchors(sizes, clas_preds.device)\n",
        "        n_classes = clas_preds.size(2)\n",
        "        return sum([self._one_loss(cp, bp, ct, bt)\n",
        "                    for (cp, bp, ct, bt) in zip(clas_preds, bbox_preds, clas_tgts, bbox_tgts)])/clas_tgts.size(0)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOGx2UGVVoHx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SigmaL1SmoothLoss(nn.Module):\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        reg_diff = torch.abs(target - output)\n",
        "        reg_loss = torch.where(torch.le(reg_diff, 1/9), 4.5 * torch.pow(reg_diff, 2), reg_diff - 1/18)\n",
        "        return reg_loss.mean()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PK85nCoVqE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ratios = [1/2,1,2]\n",
        "scales = [1,2**(-1/3), 2**(-2/3)]\n",
        "#scales = [1,2**(1/3), 2**(2/3)] #for bigger size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qHsmYxXbJKn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_predictions(output, idx, detect_thresh=0.05):\n",
        "    bbox_pred, scores, preds = process_output(output, idx, detect_thresh)\n",
        "    if len(scores) == 0: return [],[],[]\n",
        "    to_keep = nms(bbox_pred, scores)\n",
        "    return bbox_pred[to_keep], preds[to_keep], scores[to_keep]\n",
        "  \n",
        "def compute_ap(precision, recall):\n",
        "    \"Compute the average precision for `precision` and `recall` curve.\"\n",
        "    recall = np.concatenate(([0.], list(recall), [1.]))\n",
        "    precision = np.concatenate(([0.], list(precision), [0.]))\n",
        "    for i in range(len(precision) - 1, 0, -1):\n",
        "        precision[i - 1] = np.maximum(precision[i - 1], precision[i])\n",
        "    idx = np.where(recall[1:] != recall[:-1])[0]\n",
        "    ap = np.sum((recall[idx + 1] - recall[idx]) * precision[idx + 1])\n",
        "    return ap\n",
        "def compute_class_AP(model, dl, n_classes, iou_thresh=0.5, detect_thresh=0.35, num_keep=100):\n",
        "    tps, clas, p_scores = [], [], []\n",
        "    classes, n_gts = LongTensor(range(n_classes)),torch.zeros(n_classes).long()\n",
        "    with torch.no_grad():\n",
        "        for input,target in progress_bar(dl):\n",
        "            output = model(input)\n",
        "            for i in range(target[0].size(0)):\n",
        "                bbox_pred, preds, scores = get_predictions(output, i, detect_thresh)\n",
        "                tgt_bbox, tgt_clas = unpad(target[0][i], target[1][i])\n",
        "                if len(bbox_pred) != 0 and len(tgt_bbox) != 0:\n",
        "                    ious = IoU_values(bbox_pred, tgt_bbox)\n",
        "                    max_iou, matches = ious.max(1)\n",
        "                    detected = []\n",
        "                    for i in range_of(preds):\n",
        "                        if max_iou[i] >= iou_thresh and matches[i] not in detected and tgt_clas[matches[i]] == preds[i]:\n",
        "                            detected.append(matches[i])\n",
        "                            tps.append(1)\n",
        "                        else: tps.append(0)\n",
        "                    clas.append(preds.cpu())\n",
        "                    p_scores.append(scores.cpu())\n",
        "                n_gts += (tgt_clas.cpu()[:,None] == classes[None,:]).sum(0)\n",
        "    tps, p_scores, clas = torch.tensor(tps), torch.cat(p_scores,0), torch.cat(clas,0)\n",
        "    fps = 1-tps\n",
        "    idx = p_scores.argsort(descending=True)\n",
        "    tps, fps, clas = tps[idx], fps[idx], clas[idx]\n",
        "    aps = []\n",
        "    #return tps, clas\n",
        "    for cls in range(n_classes):\n",
        "        tps_cls, fps_cls = tps[clas==cls].float().cumsum(0), fps[clas==cls].float().cumsum(0)\n",
        "        if tps_cls.numel() != 0 and tps_cls[-1] != 0:\n",
        "            precision = tps_cls / (tps_cls + fps_cls + 1e-8)\n",
        "            recall = tps_cls / (n_gts[cls] + 1e-8)\n",
        "            aps.append(compute_ap(precision, recall))\n",
        "        else: aps.append(0.)\n",
        "    return aps\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_K0OHnMv51Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpad(tgt_bbox, tgt_clas, pad_idx=0):\n",
        "    i = torch.min(torch.nonzero(tgt_clas-pad_idx))\n",
        "    return tlbr2cthw(tgt_bbox[i:]), tgt_clas[i:]-1+pad_idx\n",
        "\n",
        "def _draw_outline(o:Patch, lw:int):\n",
        "    \"Outline bounding box onto image `Patch`.\"\n",
        "    o.set_path_effects([patheffects.Stroke(\n",
        "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
        "\n",
        "def draw_rect(ax:plt.Axes, b:Collection[int], color:str='white', text=None, text_size=14):\n",
        "    \"Draw bounding box on `ax`.\"\n",
        "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n",
        "    _draw_outline(patch, 4)\n",
        "    if text is not None:\n",
        "        patch = ax.text(*b[:2], text, verticalalignment='top', color=color, fontsize=text_size, weight='bold')\n",
        "        _draw_outline(patch,1)\n",
        "\n",
        "def nms(boxes, scores, thresh=0.3):\n",
        "    idx_sort = scores.argsort(descending=True)\n",
        "    boxes, scores = boxes[idx_sort], scores[idx_sort]\n",
        "    to_keep, indexes = [], torch.LongTensor(range_of(scores))\n",
        "    while len(scores) > 0:\n",
        "        to_keep.append(idx_sort[indexes[0]])\n",
        "        iou_vals = IoU_values(boxes, boxes[:1]).squeeze()\n",
        "        mask_keep = iou_vals < thresh\n",
        "        if len(mask_keep.nonzero()) == 0: break\n",
        "        boxes, scores, indexes = boxes[mask_keep], scores[mask_keep], indexes[mask_keep]\n",
        "    return LongTensor(to_keep)\n",
        "def process_output(output, i, detect_thresh=0.25):\n",
        "    clas_pred,bbox_pred,sizes = output[0][i], output[1][i], output[2]\n",
        "    anchors = create_anchors(sizes, ratios, scales).to(clas_pred.device)\n",
        "    bbox_pred = activ_to_bbox(bbox_pred, anchors)\n",
        "    clas_pred = torch.sigmoid(clas_pred)\n",
        "    detect_mask = clas_pred.max(1)[0] > detect_thresh\n",
        "    bbox_pred, clas_pred = bbox_pred[detect_mask], clas_pred[detect_mask]\n",
        "    bbox_pred = tlbr2cthw(torch.clamp(cthw2tlbr(bbox_pred), min=-1, max=1))    \n",
        "    if clas_pred.numel() == 0: return [],[],[]\n",
        "    scores, preds = clas_pred.max(1)\n",
        "    return bbox_pred, scores, preds\n",
        "def show_preds(img, output, idx, detect_thresh=0.35, classes=None, ax=None):\n",
        "    bbox_pred, scores, preds = process_output(output, idx, detect_thresh)\n",
        "    if len(scores) != 0:\n",
        "        to_keep = nms(bbox_pred, scores)\n",
        "        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
        "        t_sz = torch.Tensor([*img.size])[None].float()\n",
        "        bbox_pred[:,:2] = bbox_pred[:,:2] - bbox_pred[:,2:]/2\n",
        "        bbox_pred[:,:2] = (bbox_pred[:,:2] + 1) * t_sz/2\n",
        "        bbox_pred[:,2:] = bbox_pred[:,2:] * t_sz\n",
        "        bbox_pred = bbox_pred.long()\n",
        "    if ax is None: fig, ax = plt.subplots(1,1)\n",
        "    axs=img.show(ax=ax)\n",
        "    for bbox, c, scr in zip(bbox_pred, preds, scores):\n",
        "        txt = str(c.item()) if classes is None else classes[c.item()+1]\n",
        "        draw_rect(ax, [bbox[1],bbox[0],bbox[3],bbox[2]], text=f'{txt} {scr:.2f}')\n",
        " \n",
        "def show_results(learn, start=0, n=3, detect_thresh=0.35, figsize=(10,25)):\n",
        "    x,y = next(iter(learn.data.valid_dl)) #one_batch(DatasetType.Valid, cpu=False)\n",
        "    with torch.no_grad():\n",
        "        z = learn.model.eval()(x)\n",
        "    _,axs = plt.subplots(n, 1, figsize=figsize)\n",
        "    for i in range(n):\n",
        "        img,bbox = learn.data.valid_ds[start+i]\n",
        "        #img.show(ax=axs[i,0], y=bbox)\n",
        "        show_preds(img, z, start+i, detect_thresh=detect_thresh, classes=learn.data.classes, ax=axs[i])\n",
        "def gun_detection_on_video(name,detect_thresh):\n",
        "  cap= cv2.VideoCapture(name)\n",
        "  i=0\n",
        "  while (cap.isOpened()):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False:\n",
        "        break\n",
        "    cv2.imwrite(f'temp/{i}.jpg',frame)\n",
        "    i+=1\n",
        "  for a in range(i):\n",
        "      frame= cv2.imread(f'temp/{a}.jpg')\n",
        "      im=open_image(f'temp/{a}.jpg')\n",
        "      a+=1\n",
        "      (H, W) =im.shape[:2]\n",
        "      output=learn.model((im.data[None]).cuda())\n",
        "      bbox_pred, scores, preds = process_output(output, 0, detect_thresh=detect_thresh)\n",
        "      if len(scores) != 0:\n",
        "        to_keep = nms(bbox_pred, scores)\n",
        "        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
        "        t_sz = torch.Tensor([*im.size])[None].float()\n",
        "        bbox_pred[:,:2] = bbox_pred[:,:2] - bbox_pred[:,2:]/2\n",
        "        bbox_pred[:,:2] = (bbox_pred[:,:2] + 1) * t_sz/2\n",
        "        bbox_pred[:,2:] = bbox_pred[:,2:] * t_sz\n",
        "        bbox_pred = bbox_pred.long()\n",
        "        for bbox, c, scr in zip(bbox_pred, preds, scores):\n",
        "          txt = str(c.item()) if classes is None else classes[c.item()+1]\n",
        "          text=f'{txt} {scr:.2f}'\n",
        "          cv2.rectangle(frame,(bbox[1], bbox[0]), (bbox[3]+bbox[1]-1, bbox[2]+bbox[0]-1),(0,255,0),2)\n",
        "          cv2.putText(frame,text, (bbox[1],bbox[0]),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "          b0=bbox[1]\n",
        "          b1=bbox[0]\n",
        "          b2=bbox[3]+bbox[1]-1\n",
        "          b3=bbox[2]+bbox[0]-1\n",
        "          bbox[0]=b0\n",
        "          bbox[1]=b1\n",
        "          bbox[2]=b2\n",
        "          bbox[3]=b3\n",
        "      height, width, layers = frame.shape\n",
        "      size = (width,height)\n",
        "      cv2.imwrite(f'temp/framebb{a}.jpg',frame)\n",
        "  pathOut='output.avi'\n",
        "  out = cv2.VideoWriter(pathOut,cv2.VideoWriter_fourcc(*'DIVX'), 24.0, size)\n",
        "  for a in range(i):\n",
        "    # writing to a image array\n",
        "    frame=cv2.imread(f'temp/framebb{a}.jpg')\n",
        "    out.write(frame)\n",
        "  out.release()\n",
        "  \n",
        "def gun_detection_on_image(name,detect_thresh):\n",
        "      frame= cv2.imread(f'{name}')\n",
        "      im=open_image(f'{name}')\n",
        "      (H, W) =im.shape[:2]\n",
        "      output=learn.model((im.data[None]).cuda())\n",
        "      bbox_pred, scores, preds = process_output(output, 0, detect_thresh=detect_thresh)\n",
        "      if len(scores) != 0:\n",
        "        to_keep = nms(bbox_pred, scores)\n",
        "        bbox_pred, preds, scores = bbox_pred[to_keep].cpu(), preds[to_keep].cpu(), scores[to_keep].cpu()\n",
        "        t_sz = torch.Tensor([*im.size])[None].float()\n",
        "        bbox_pred[:,:2] = bbox_pred[:,:2] - bbox_pred[:,2:]/2\n",
        "        bbox_pred[:,:2] = (bbox_pred[:,:2] + 1) * t_sz/2\n",
        "        bbox_pred[:,2:] = bbox_pred[:,2:] * t_sz\n",
        "        bbox_pred = bbox_pred.long()\n",
        "        for bbox, c, scr in zip(bbox_pred, preds, scores):\n",
        "          txt = str(c.item()) if classes is None else classes[c.item()+1]\n",
        "          text=f'{txt} {scr:.2f}'\n",
        "          cv2.rectangle(frame,(bbox[1], bbox[0]), (bbox[3]+bbox[1]-1, bbox[2]+bbox[0]-1),(0,255,0),2)\n",
        "          cv2.putText(frame,text, (bbox[1],bbox[0]),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "          b0=bbox[1]\n",
        "          b1=bbox[0]\n",
        "          b2=bbox[3]+bbox[1]-1\n",
        "          b3=bbox[2]+bbox[0]-1\n",
        "          bbox[0]=b0\n",
        "          bbox[1]=b1\n",
        "          bbox[2]=b2\n",
        "          bbox[3]=b3\n",
        "      height, width, layers = frame.shape\n",
        "      size = (width,height)\n",
        "      cv2.imwrite(f'output.jpg',frame)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NS-_Xuo6b18E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install youtube-dl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhdIzuQib4rW",
        "colab_type": "text"
      },
      "source": [
        "# Weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "786y3djQnURT",
        "colab_type": "code",
        "outputId": "c5f95e0b-5c88-412b-b15d-0b8690acb90a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        }
      },
      "source": [
        "!wget wget https://www.dropbox.com/s/7f42lcdjx5ou5yl/export.pkl"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-27 22:19:28--  http://wget/\n",
            "Resolving wget (wget)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘wget’\n",
            "--2019-06-27 22:19:28--  https://www.dropbox.com/s/7f42lcdjx5ou5yl/export.pkl\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.8.1, 2620:100:6018:1::a27d:301\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.8.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/7f42lcdjx5ou5yl/export.pkl [following]\n",
            "--2019-06-27 22:19:28--  https://www.dropbox.com/s/raw/7f42lcdjx5ou5yl/export.pkl\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com/cd/0/inline/AjrRT_m7YT-xtuW9to2PP9bm8jyVdpBhFat7ivAEniCylkCr18fjxMI-27Cem-E92s_HQltQOOxJGBPJOsy6V9LK7DFR6Q5mn8-KuK546q8xZQ/file# [following]\n",
            "--2019-06-27 22:19:28--  https://ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com/cd/0/inline/AjrRT_m7YT-xtuW9to2PP9bm8jyVdpBhFat7ivAEniCylkCr18fjxMI-27Cem-E92s_HQltQOOxJGBPJOsy6V9LK7DFR6Q5mn8-KuK546q8xZQ/file\n",
            "Resolving ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com (ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com)... 162.125.8.6, 2620:100:601b:6::a27d:806\n",
            "Connecting to ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com (ucb0cdd6326e6c4270a45ef70f22.dl.dropboxusercontent.com)|162.125.8.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 147373163 (141M) [text/plain]\n",
            "Saving to: ‘export.pkl’\n",
            "\n",
            "export.pkl          100%[===================>] 140.55M  46.3MB/s    in 3.0s    \n",
            "\n",
            "2019-06-27 22:19:32 (46.3 MB/s) - ‘export.pkl’ saved [147373163/147373163]\n",
            "\n",
            "FINISHED --2019-06-27 22:19:32--\n",
            "Total wall clock time: 4.2s\n",
            "Downloaded: 1 files, 141M in 3.0s (46.3 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGjRGMyTq4Ya",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir model\n",
        "path=Path('model')\n",
        "!mv export.pkl model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBQB9u0goPMy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn=load_learner(path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZziijJmvgAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes=['bg','pistol','rifle']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hkusrzQDtHd",
        "colab_type": "text"
      },
      "source": [
        "# Video\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1If9UmELKGbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hgbylg8SB1JX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "b5f81060-6b94-4931-9ad2-d954dd87b79b"
      },
      "source": [
        "#@title Entre the url of the video\n",
        "#@markdown We have provided an example.\n",
        "\n",
        "url = 'https://www.youtube.com/watch?v=8ZR9jLquv8Y'#@param {type: \"string\"}\n",
        "!youtube-dl -o test {url} \n",
        "#@markdown ---\n",
        "#@title Enter the name of the video and the threshold. We suggest to use 0.5\n",
        "\n",
        "name = 'test.mkv'  #@param {type: \"string\"}\n",
        "detect_thresh = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.05}\n"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[youtube] 8ZR9jLquv8Y: Downloading webpage\n",
            "[youtube] 8ZR9jLquv8Y: Downloading video info webpage\n",
            "[youtube] 8ZR9jLquv8Y: Downloading MPD manifest\n",
            "\u001b[0;33mWARNING:\u001b[0m Requested formats are incompatible for merge and will be merged into mkv.\n",
            "[download] test.mkv has already been downloaded and merged\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eWw2zUznxFx7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b0c37e44-d507-44a7-95a4-efafd074ea03"
      },
      "source": [
        "%%time\n",
        "gun_detection_on_video(name,detect_thresh)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 33.5 s, sys: 9.29 s, total: 42.8 s\n",
            "Wall time: 42.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBS5heseJL_t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r temp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niUOqwKkFyvY",
        "colab_type": "text"
      },
      "source": [
        "# Image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6GpvYNrF1F7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "outputId": "96edfe2a-0248-432f-f284-cd5980e01071"
      },
      "source": [
        "#@title Entre the url of the image\n",
        "#@markdown We have provided an example.\n",
        "\n",
        "url = 'https://img.youtube.com/vi/oEq4KmGZ4a0/hqdefault.jpg'#@param {type: \"string\"}\n",
        "!wget {url} -O test.jpg\n",
        "#@markdown ---\n",
        "#@title Enter the name of the video and the threshold. We suggest to use 0.5\n",
        "\n",
        "name = 'test.jpg'  #@param {type: \"string\"}\n",
        "detect_thresh = 0.5 #@param {type:\"slider\", min:0, m"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-27 22:59:25--  https://img.youtube.com/vi/oEq4KmGZ4a0/hqdefault.jpg\n",
            "Resolving img.youtube.com (img.youtube.com)... 108.177.120.138, 173.194.192.100, 173.194.192.101, ...\n",
            "Connecting to img.youtube.com (img.youtube.com)|108.177.120.138|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10772 (11K) [image/jpeg]\n",
            "Saving to: ‘test.jpg’\n",
            "\n",
            "\rtest.jpg              0%[                    ]       0  --.-KB/s               \rtest.jpg            100%[===================>]  10.52K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-06-27 22:59:25 (79.9 MB/s) - ‘test.jpg’ saved [10772/10772]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um5cJw5HGIcn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "gun_detection_on_image(name,detect_thresh)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BwDNiaIKAzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}